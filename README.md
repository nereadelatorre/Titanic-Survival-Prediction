# Predicci칩n de Supervivencia en el Titanic - An치lisis y Clasificaci칩n

Este proyecto consiste en un an치lisis exhaustivo y la implementaci칩n de m칰ltiples modelos de Machine Learning para predecir la supervivencia de los pasajeros del Titanic. Fue desarrollado como parte de la asignatura de **Aprendizaje Computacional**.

![Python](https://img.shields.io/badge/Python-3.8%2B-blue)
![Jupyter](https://img.shields.io/badge/Jupyter-Notebook-orange)
![Scikit-Learn](https://img.shields.io/badge/Library-Scikit__Learn-yellow)

## Descripci칩n
El objetivo principal es aplicar t칠cnicas de **An치lisis Exploratorio de Datos (EDA)**, **Preprocesamiento** y **Modelado Predictivo** para clasificar si un pasajero sobrevivi칩 o no, bas치ndose en caracter칤sticas como la edad, el sexo, la clase social y el precio del billete.

El proyecto abarca desde la limpieza de datos (imputaci칩n de nulos) hasta la comparaci칩n de m칠tricas de rendimiento (F1-Score, Accuracy) entre diferentes algoritmos.

## Librerias utilizadas
* **Lenguaje:** Python
* **Librer칤as de An치lisis:** Pandas, NumPy
* **Visualizaci칩n:** Matplotlib, Seaborn
* **Machine Learning:** Scikit-learn (Sklearn)

## Metodolog칤a
El flujo de trabajo seguido en el notebook (`APC_Practica_1_2024.ipynb`) incluye:

1.  **EDA (Exploratory Data Analysis):**
    * An치lisis de correlaciones (mapas de calor).
    * Visualizaci칩n de distribuci칩n de supervivientes por g칠nero y clase.
    * Detecci칩n de valores nulos (Age, Cabin, Embarked).

2.  **Preprocesamiento:**
    * **Imputaci칩n:** Uso de `KNNImputer` y promedios condicionados para rellenar valores faltantes en 'Age' y 'Embarked'.
    * **Ingenier칤a de Atributos:** Creaci칩n de la variable `HasFamily` para determinar si el pasajero viajaba solo.
    * **Codificaci칩n:** Label Encoding para variables binarias y One-Hot Encoding para categ칩ricas.
    * **Escalado:** Estandarizaci칩n de variables num칠ricas ('Age', 'Fare') usando `StandardScaler`.

3.  **Modelado:**
    Se entrenaron y compararon los siguientes modelos:
    * Regresi칩n Log칤stica
    * 츼rboles de Decisi칩n (Decision Tree)
    * Random Forest
    * K-Nearest Neighbors (KNN)
    * Support Vector Machines (SVM)
    * Gradient Boosting

## 游늵 Resultados Destacados
* **Factor Clave:** El g칠nero y la clase social fueron determinantes; las mujeres de primera clase tuvieron la tasa de supervivencia m치s alta.
* **Mejor Modelo:** El modelo **Gradient Boosting** y **Random Forest** mostraron un rendimiento superior en t칠rminos de F1-Score en comparaci칩n con modelos m치s simples como KNN.
* **Ingenier칤a de caracter칤sticas:** La variable derivada `HasFamily` mostr칩 una correlaci칩n positiva con la supervivencia.

## Instalaci칩n y Uso
1.  Clona el repositorio:
    ```bash
    git clone [https://github.com/tu-usuario/Titanic-Survival-Prediction.git](https://github.com/tu-usuario/Titanic-Survival-Prediction.git)
    ```
2.  Instala las dependencias:
    ```bash
    pip install pandas numpy matplotlib seaborn scikit-learn
    ```
3.  Ejecuta el notebook:
    ```bash
    jupyter notebook APC_Practica_1_2024.ipynb
    ```

## Autores
Trabajo realizado por:
* Nerea de la Torre Veguillas
* Mara Montero Jurado
* J칰lia Mor치n Fluvi
* Adri치n Prego Gallart

Matem치tica Computacional y An치lisis de datos, UAB
